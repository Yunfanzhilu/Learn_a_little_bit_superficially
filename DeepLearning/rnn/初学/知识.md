## 1.什么是RNN

​      RNN是专门用来处理带有序列模式数据，同时也需要使用权重共享来减少需要权重的数量。

RNN Cell本质是一个线性层(这个线性层是共享的)，可以把某一个维度映射到另一个维度。

序列的每一项都送到RNN Cell中，因为序列之间每一项都和前一项存在着联系，例如先

x2计算出的h2不仅要包含x2的信息还要包含x1的信息（h1不仅输出了还送到了x2的运算中）
![img](rnn01.png)
![img](rnn02.png)
* 因为xt.shape=[input_size,1]，ht-1.shape=[hidden_size,1]
* 所以Wih.shape=[hidden_size,input_size],这样你才能得到Wihxt.shape=[hidden_size,1]


* 因为ht-1输入是hidden_size,1,输出是hidden_size,1
* 所以whh.shape=[hidden_size,hidden_size]

_rnn中常用tanh作为激活函数,tanh的取值的在[-1,1]之间,一定要有激活函数，否则再多的隐层也仅仅只是线性变换，可以看做一层线性层_


## 2.构建rnn
  pytorch中有两种构建rnn的方式
![img](RNNcell.png)
- torch.nn.RNNcell(input_size=input_size,hidden_size=hidden_size) 详见torch.nn.RNNCell_BasePytorch.py

![img](RNN1.png)
![img](RNN2.png)
- 直接使用torch.n.RNN,详见torch.nn.RNN.py
![img](numLayers.png)
- _注意numLayers的含义_
